{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baochi0212/deep-learning-tourxQA/blob/master/how_to_run_tourxQA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSbpu9EtWOoy",
        "outputId": "ebe7b2c2-deec-41d4-d46d-5d1cad29e3ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.8 MB 20.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 452 kB 59.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 191 kB 68.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 598 kB 46.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 11.0 MB 65.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 410 kB 70.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 24.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 79.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 57.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 76.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 75.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 981 kB 62.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 18.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 228 kB 78.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 385 kB 76.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.7 MB 57.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 85 kB 4.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 62.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 16.7 MB 51.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 172 kB 78.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 85 kB 121 kB/s \n",
            "\u001b[K     |████████████████████████████████| 41 kB 615 kB/s \n",
            "\u001b[K     |████████████████████████████████| 114 kB 80.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 60.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 65.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 591 kB 79.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 82 kB 520 kB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 75.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 575 kB 78.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 210 kB 78.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 147 kB 46.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 147 kB 80.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 146 kB 79.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 125 kB 67.4 MB/s \n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers datasets accelerate farm-haystack datasets underthesea pytorch-crf nlpaug"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hvs0SAaggHNm"
      },
      "source": [
        "###tourxQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tcJ8kXdg4ga",
        "outputId": "b0c092fb-5684-4902-9c7e-17405ffa639e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec 28 07:06:36 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    26W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5p7rOGFSwPz",
        "outputId": "4abdb870-1e4e-4212-b4c7-b703908ab5d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deep-learning-tourxQA'...\n",
            "remote: Enumerating objects: 4926, done.\u001b[K\n",
            "remote: Counting objects: 100% (1056/1056), done.\u001b[K\n",
            "remote: Compressing objects: 100% (464/464), done.\u001b[K\n",
            "remote: Total 4926 (delta 631), reused 972 (delta 551), pack-reused 3870\u001b[K\n",
            "Receiving objects: 100% (4926/4926), 75.73 MiB | 17.30 MiB/s, done.\n",
            "Resolving deltas: 100% (3050/3050), done.\n",
            "Checking out files: 100% (368/368), done.\n"
          ]
        }
      ],
      "source": [
        "#git clone https://username:password@github.com/username/repository.git\n",
        "!git clone https://baochi0212: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@github.com/baochi0212/deep-learning-tourxQA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oXsC105SxZo",
        "outputId": "97d5ae30-e46f-48cb-887a-e27a6defa2f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deep-learning-tourxQA\n"
          ]
        }
      ],
      "source": [
        "%cd /content/deep-learning-tourxQA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Msr9GhtOS4aE",
        "outputId": "e0a32d9c-3d84-441d-9c4b-944c9c480897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch 'feature/distillation' set up to track remote branch 'feature/distillation' from 'origin'.\n",
            "Switched to a new branch 'feature/distillation'\n"
          ]
        }
      ],
      "source": [
        "#choose your branch\n",
        "!git checkout feature/distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1sjS6CCTWZo",
        "outputId": "7804cd49-2428-428e-ca0a-8ac414bbdc87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: dir=/content/deep-learning-tourxQA\n",
            "env: src=/content/deep-learning-tourxQA/src\n",
            "env: source=/content/deep-learning-tourxQA/source\n",
            "env: data_dir=/content/deep-learning-tourxQA/data/processed\n"
          ]
        }
      ],
      "source": [
        "%env dir=/content/deep-learning-tourxQA\n",
        "%env src=/content/deep-learning-tourxQA/src\n",
        "%env source=/content/deep-learning-tourxQA/source\n",
        "%env data_dir=/content/deep-learning-tourxQA/data/processed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDRjAEmEg_xa"
      },
      "source": [
        "####QA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raLxToJXtdyd",
        "outputId": "b4fced63-44eb-41bf-f520-ca2788d93fbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UbXwx-W1VK2",
        "outputId": "7ad27c4a-c942-45d9-c8d3-ebb60d92fe90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/deep-learning-tourxQA/source\n"
          ]
        }
      ],
      "source": [
        "%cd source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GlRd1494thqz"
      },
      "outputs": [],
      "source": [
        "!bash runtime/qa_run/run_bert.sh 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMMQuHLkmU8K"
      },
      "outputs": [],
      "source": [
        "!bash runtime/qa_run/run_electra.sh 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fs0a4JFnobZM"
      },
      "outputs": [],
      "source": [
        "!bash runtime/qa_run/run_xlm_base.sh 0 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmVuJkyT4N41"
      },
      "outputs": [],
      "source": [
        "!bash runtime/qa_run/run_xlm_large.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Rew6_Qtts9r"
      },
      "source": [
        "####IDSF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JixqLQCBCWXJ",
        "outputId": "137a88b5-6588-45eb-cd95-90aa45272a8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrcdM40E3M-p",
        "outputId": "0514c689-b36e-4096-a136-e88c252bc37a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/deep-learning-tourxQA/source\n"
          ]
        }
      ],
      "source": [
        "%cd source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HV60iqC_ZUyL"
      },
      "outputs": [],
      "source": [
        "!bash runtime/idsf_run/run_gru.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cg6KvOw5gp3",
        "outputId": "764b40e4-5f0b-4903-8109-44dbb8c9c7b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing JointPhoBERT: ['lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing JointPhoBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing JointPhoBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of JointPhoBERT were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['crf.end_transitions', 'slot_classifier.linear_slot.weight', 'intent_classifier.linear.weight', 'crf.transitions', 'intent_classifier.linear.bias', 'crf.start_transitions', 'slot_classifier.linear.weight', 'slot_classifier.linear.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing JointPhoBERT: ['lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing JointPhoBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing JointPhoBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of JointPhoBERT were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['crf.end_transitions', 'slot_classifier.linear_slot.weight', 'intent_classifier.linear.weight', 'crf.transitions', 'intent_classifier.linear.bias', 'crf.start_transitions', 'slot_classifier.linear.weight', 'slot_classifier.linear.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "MODEL:  JointPhoBERT(\n",
            "  (roberta): RobertaModel(\n",
            "    (embeddings): RobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
            "      (position_embeddings): Embedding(258, 768, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): RobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): RobertaPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (intent_classifier): IntentClassifier(\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (linear): Linear(in_features=768, out_features=25, bias=True)\n",
            "  )\n",
            "  (slot_classifier): SlotClassifier(\n",
            "    (linear_slot): Linear(in_features=768, out_features=200, bias=False)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (linear): Linear(in_features=200, out_features=142, bias=True)\n",
            "  )\n",
            "  (crf): CRF(num_tags=142)\n",
            ")\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torchcrf/__init__.py:249: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at ../aten/src/ATen/native/TensorCompare.cpp:413.)\n",
            "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n",
            "Evaluating: 100% 16/16 [00:02<00:00,  6.76it/s]\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: UNK seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "DEV:  {'loss': 3.8585782945156097, 'intent_acc': 0.222, 'slot_accuracy': 0.0, 'slot_precision': 0.0015460729746444033, 'slot_recall': 0.005837711617046118, 'slot_f1': 0.002444688913335778, 'semantic_frame_acc': 0.0, 'mean_intent_slot': 0.11222234445666789}\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 0\n",
            "Iteration: 100% 139/139 [00:41<00:00,  3.36it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 1\n",
            "\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  9.01it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  9.24it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  9.28it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  9.35it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  9.38it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  9.41it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:00,  9.38it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  9.31it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:00<00:00,  9.31it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  9.29it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  9.19it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  9.26it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  9.13it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  9.22it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  9.43it/s]\n",
            "DEV:  {'loss': 0.7701187431812286, 'intent_acc': 0.9, 'slot_accuracy': 0.006, 'slot_precision': 0.09925841414717627, 'slot_recall': 0.10157618213660245, 'slot_f1': 0.10040392383150606, 'semantic_frame_acc': 0.004, 'mean_intent_slot': 0.5002019619157531}\n",
            "semantic_frame_acc increased (inf --> 0.004000).  Saving model ...\n",
            "Iteration: 100% 139/139 [00:45<00:00,  3.04it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 2\n",
            "Iteration:   1% 1/139 [00:00<00:41,  3.32it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.95it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  9.01it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  9.12it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  9.16it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  9.13it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  8.86it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:01,  8.97it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  8.98it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:00<00:00,  9.05it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  9.16it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  9.07it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  9.16it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  9.19it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  9.20it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  9.31it/s]\n",
            "DEV:  {'loss': 0.44878896325826645, 'intent_acc': 0.944, 'slot_accuracy': 0.12, 'slot_precision': 0.44438106103822017, 'slot_recall': 0.45475773496789257, 'slot_f1': 0.4495095210617426, 'semantic_frame_acc': 0.106, 'mean_intent_slot': 0.6967547605308713}\n",
            "semantic_frame_acc increased (0.004000 --> 0.106000).  Saving model ...\n",
            "Iteration: 100% 139/139 [00:47<00:00,  2.95it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 3\n",
            "Iteration:   1% 2/139 [00:00<00:42,  3.22it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.26it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  8.78it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  8.97it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  9.04it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  9.08it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  9.11it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:00,  9.12it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  9.03it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:00<00:00,  9.03it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  9.03it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  8.99it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  9.03it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  9.08it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  9.09it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  9.21it/s]\n",
            "DEV:  {'loss': 0.29919303953647614, 'intent_acc': 0.976, 'slot_accuracy': 0.38, 'slot_precision': 0.694634703196347, 'slot_recall': 0.7104495037945125, 'slot_f1': 0.7024531024531024, 'semantic_frame_acc': 0.372, 'mean_intent_slot': 0.8392265512265512}\n",
            "semantic_frame_acc increased (0.106000 --> 0.372000).  Saving model ...\n",
            "Iteration: 100% 139/139 [00:47<00:00,  2.95it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 4\n",
            "Iteration:   2% 3/139 [00:00<00:42,  3.17it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.47it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  8.72it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  8.86it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  8.97it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  8.90it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  8.87it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:01,  8.92it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  9.02it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:01<00:00,  8.97it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  9.02it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  8.89it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  8.73it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  8.84it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  8.83it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  9.08it/s]\n",
            "DEV:  {'loss': 0.24587811902165413, 'intent_acc': 0.964, 'slot_accuracy': 0.578, 'slot_precision': 0.7911899313501144, 'slot_recall': 0.8073555166374781, 'slot_f1': 0.7991909852643744, 'semantic_frame_acc': 0.564, 'mean_intent_slot': 0.8815954926321872}\n",
            "semantic_frame_acc increased (0.372000 --> 0.564000).  Saving model ...\n",
            "Iteration: 100% 139/139 [00:47<00:00,  2.93it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 5\n",
            "Iteration:   3% 4/139 [00:01<00:42,  3.18it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.56it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  8.91it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  8.79it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  8.94it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  8.83it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  8.95it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:01,  8.88it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  8.85it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:01<00:00,  8.81it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  8.79it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  8.84it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  8.65it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  8.65it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  8.74it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  8.98it/s]\n",
            "DEV:  {'loss': 0.1734656780026853, 'intent_acc': 0.984, 'slot_accuracy': 0.616, 'slot_precision': 0.7950727883538634, 'slot_recall': 0.8289550496205488, 'slot_f1': 0.8116604744212633, 'semantic_frame_acc': 0.606, 'mean_intent_slot': 0.8978302372106317}\n",
            "semantic_frame_acc increased (0.564000 --> 0.606000).  Saving model ...\n",
            "Iteration: 100% 139/139 [00:47<00:00,  2.92it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 6\n",
            "Iteration:   4% 5/139 [00:01<00:42,  3.14it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.57it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  8.37it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  8.72it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  8.80it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  8.77it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  8.88it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:01,  8.96it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  8.90it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:01<00:00,  8.92it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  8.96it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  8.84it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  8.93it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  8.95it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  8.92it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  9.05it/s]\n",
            "DEV:  {'loss': 0.1715868003666401, 'intent_acc': 0.976, 'slot_accuracy': 0.648, 'slot_precision': 0.8282138794084186, 'slot_recall': 0.8499708114419148, 'slot_f1': 0.8389513108614233, 'semantic_frame_acc': 0.638, 'mean_intent_slot': 0.9074756554307116}\n",
            "semantic_frame_acc increased (0.606000 --> 0.638000).  Saving model ...\n",
            "Iteration: 100% 139/139 [00:48<00:00,  2.86it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 7\n",
            "Iteration:   4% 6/139 [00:01<00:41,  3.17it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.47it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  8.64it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  8.80it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  8.86it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  8.92it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  8.87it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:01,  8.91it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  8.98it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:01<00:00,  9.00it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  8.93it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  8.93it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  8.94it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  8.87it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  8.96it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  9.10it/s]\n",
            "DEV:  {'loss': 0.16061683045700192, 'intent_acc': 0.982, 'slot_accuracy': 0.702, 'slot_precision': 0.8665118978525828, 'slot_recall': 0.8715703444249854, 'slot_f1': 0.8690337601862632, 'semantic_frame_acc': 0.692, 'mean_intent_slot': 0.9255168800931316}\n",
            "semantic_frame_acc increased (0.638000 --> 0.692000).  Saving model ...\n",
            "Iteration: 100% 139/139 [00:47<00:00,  2.91it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 8\n",
            "Iteration:   5% 7/139 [00:02<00:41,  3.14it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.29it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  8.43it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  8.77it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  8.76it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  8.82it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  8.85it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:01,  8.92it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  8.83it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:01<00:00,  8.89it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  8.85it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  8.79it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  8.90it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  8.92it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  8.95it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  9.05it/s]\n",
            "DEV:  {'loss': 0.13840984110720456, 'intent_acc': 0.982, 'slot_accuracy': 0.71, 'slot_precision': 0.8753606462781304, 'slot_recall': 0.8855808523058961, 'slot_f1': 0.8804410911201394, 'semantic_frame_acc': 0.698, 'mean_intent_slot': 0.9312205455600697}\n",
            "semantic_frame_acc increased (0.692000 --> 0.698000).  Saving model ...\n",
            "Iteration: 100% 139/139 [00:48<00:00,  2.86it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 9\n",
            "Iteration:   6% 8/139 [00:02<00:41,  3.15it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.42it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  8.76it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  8.86it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  8.91it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  8.98it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  9.02it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:00,  9.02it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  8.96it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:01<00:00,  8.98it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  9.03it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  8.98it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  8.83it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  8.81it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  8.77it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  9.07it/s]\n",
            "DEV:  {'loss': 0.13677124155219644, 'intent_acc': 0.98, 'slot_accuracy': 0.732, 'slot_precision': 0.8792215226101889, 'slot_recall': 0.8966725043782837, 'slot_f1': 0.8878612716763006, 'semantic_frame_acc': 0.72, 'mean_intent_slot': 0.9339306358381503}\n",
            "semantic_frame_acc increased (0.698000 --> 0.720000).  Saving model ...\n",
            "Iteration: 100% 139/139 [00:47<00:00,  2.90it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 10\n",
            "Iteration:   6% 9/139 [00:02<00:41,  3.14it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.43it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  8.40it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  8.67it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  8.75it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  8.74it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  8.88it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:01,  8.83it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  8.93it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:01<00:00,  8.92it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  8.90it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  8.93it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  8.98it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  8.82it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  8.72it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  9.00it/s]\n",
            "DEV:  {'loss': 0.15860780701041222, 'intent_acc': 0.974, 'slot_accuracy': 0.744, 'slot_precision': 0.8948275862068965, 'slot_recall': 0.9089316987740805, 'slot_f1': 0.9018245004344049, 'semantic_frame_acc': 0.73, 'mean_intent_slot': 0.9379122502172024}\n",
            "semantic_frame_acc increased (0.720000 --> 0.730000).  Saving model ...\n",
            "Iteration: 100% 139/139 [00:47<00:00,  2.90it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 11\n",
            "Iteration:   7% 10/139 [00:03<00:41,  3.14it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.49it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  8.72it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  8.83it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  8.91it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  8.82it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  8.88it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:01,  8.90it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  8.90it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:01<00:00,  8.93it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  8.98it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  8.82it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  8.91it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  8.91it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  8.81it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  9.07it/s]\n",
            "DEV:  {'loss': 0.1579073998145759, 'intent_acc': 0.982, 'slot_accuracy': 0.538, 'slot_precision': 0.8178477690288714, 'slot_recall': 0.9095154699357851, 'slot_f1': 0.861249309010503, 'semantic_frame_acc': 0.528, 'mean_intent_slot': 0.9216246545052516}\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Iteration: 100% 139/139 [00:46<00:00,  3.01it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 12\n",
            "Iteration:   8% 11/139 [00:03<00:41,  3.11it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.29it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  8.47it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  8.70it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  8.76it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  8.76it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  8.39it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:01,  8.61it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  8.72it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:01<00:00,  8.78it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  8.83it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  8.76it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  8.86it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  8.92it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  8.90it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  8.97it/s]\n",
            "DEV:  {'loss': 0.1561396555043757, 'intent_acc': 0.978, 'slot_accuracy': 0.75, 'slot_precision': 0.8913288288288288, 'slot_recall': 0.9241097489784005, 'slot_f1': 0.9074233304671826, 'semantic_frame_acc': 0.736, 'mean_intent_slot': 0.9427116652335913}\n",
            "semantic_frame_acc increased (0.730000 --> 0.736000).  Saving model ...\n",
            "Iteration: 100% 139/139 [00:48<00:00,  2.89it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 13\n",
            "Iteration:   9% 12/139 [00:03<00:40,  3.13it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.35it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  8.60it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  8.74it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  8.80it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  8.73it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  8.76it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:01,  8.81it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  8.86it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:01<00:00,  8.87it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  8.87it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  8.86it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  8.89it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  8.79it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  8.82it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  8.98it/s]\n",
            "DEV:  {'loss': 0.16897775419056416, 'intent_acc': 0.974, 'slot_accuracy': 0.74, 'slot_precision': 0.8899548532731377, 'slot_recall': 0.9206071220081729, 'slot_f1': 0.9050215208034433, 'semantic_frame_acc': 0.724, 'mean_intent_slot': 0.9395107604017217}\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Iteration: 100% 139/139 [00:47<00:00,  2.94it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 14\n",
            "Iteration:   9% 13/139 [00:04<00:40,  3.13it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.19it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  8.41it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  8.68it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  8.71it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  8.75it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  8.76it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:01,  8.37it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  8.56it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:01<00:00,  8.68it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  8.66it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  8.76it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  8.83it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  8.81it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  8.89it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  8.91it/s]\n",
            "DEV:  {'loss': 0.18930782447569072, 'intent_acc': 0.974, 'slot_accuracy': 0.714, 'slot_precision': 0.8928571428571429, 'slot_recall': 0.9340338587273789, 'slot_f1': 0.912981455064194, 'semantic_frame_acc': 0.7, 'mean_intent_slot': 0.943490727532097}\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Iteration: 100% 139/139 [00:47<00:00,  2.94it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 15\n",
            "Iteration:  10% 14/139 [00:04<00:39,  3.13it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.33it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  8.40it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  8.67it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  8.79it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  8.82it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  8.87it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:01,  8.87it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  8.91it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:01<00:00,  8.90it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  8.84it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  8.85it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  8.88it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  8.92it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  8.92it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  9.05it/s]\n",
            "DEV:  {'loss': 0.17631928948685527, 'intent_acc': 0.974, 'slot_accuracy': 0.692, 'slot_precision': 0.9002898550724637, 'slot_recall': 0.9065966141272621, 'slot_f1': 0.9034322280395579, 'semantic_frame_acc': 0.676, 'mean_intent_slot': 0.938716114019779}\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Iteration: 100% 139/139 [00:46<00:00,  2.99it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 16\n",
            "Iteration:  11% 15/139 [00:04<00:39,  3.12it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.43it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  8.72it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  8.40it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  8.64it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  8.63it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  8.73it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:01,  8.76it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  8.74it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:01<00:00,  8.75it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  8.83it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  8.81it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  8.83it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  8.81it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  8.84it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  8.91it/s]\n",
            "DEV:  {'loss': 0.15930844494141638, 'intent_acc': 0.974, 'slot_accuracy': 0.778, 'slot_precision': 0.9214659685863874, 'slot_recall': 0.9246935201401051, 'slot_f1': 0.9230769230769231, 'semantic_frame_acc': 0.76, 'mean_intent_slot': 0.9485384615384616}\n",
            "semantic_frame_acc increased (0.736000 --> 0.760000).  Saving model ...\n",
            "Iteration: 100% 139/139 [00:48<00:00,  2.88it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 17\n",
            "Iteration:  12% 16/139 [00:05<00:39,  3.14it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.29it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  8.73it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  8.67it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  8.83it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  8.85it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  8.80it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:01,  8.85it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  8.74it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:01<00:00,  8.84it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  8.89it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  8.93it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  8.92it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  8.95it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  8.94it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  9.03it/s]\n",
            "DEV:  {'loss': 0.156393613666296, 'intent_acc': 0.978, 'slot_accuracy': 0.754, 'slot_precision': 0.8976377952755905, 'slot_recall': 0.9316987740805605, 'slot_f1': 0.9143511887711258, 'semantic_frame_acc': 0.74, 'mean_intent_slot': 0.9461755943855629}\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Iteration: 100% 139/139 [00:46<00:00,  3.00it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 18\n",
            "Iteration:  12% 17/139 [00:05<00:38,  3.13it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.24it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  8.63it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  8.77it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  8.85it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  8.88it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  8.92it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:01,  8.93it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  8.74it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:01<00:00,  8.74it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  8.81it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  8.89it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  8.95it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  8.91it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  8.92it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  9.04it/s]\n",
            "DEV:  {'loss': 0.1675405642017722, 'intent_acc': 0.976, 'slot_accuracy': 0.808, 'slot_precision': 0.9145785876993167, 'slot_recall': 0.9375364856976065, 'slot_f1': 0.925915249351398, 'semantic_frame_acc': 0.792, 'mean_intent_slot': 0.950957624675699}\n",
            "semantic_frame_acc increased (0.760000 --> 0.792000).  Saving model ...\n",
            "Iteration: 100% 139/139 [00:48<00:00,  2.89it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 19\n",
            "Iteration:  13% 18/139 [00:05<00:38,  3.12it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.17it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  8.62it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  8.76it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  8.83it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  8.59it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  8.68it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:01,  8.77it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  8.78it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:01<00:00,  8.84it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  8.75it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  8.70it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  8.70it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  8.67it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  8.67it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  8.90it/s]\n",
            "DEV:  {'loss': 0.1365254969568923, 'intent_acc': 0.98, 'slot_accuracy': 0.814, 'slot_precision': 0.9226393629124005, 'slot_recall': 0.9468768242848803, 'slot_f1': 0.9346009795447998, 'semantic_frame_acc': 0.798, 'mean_intent_slot': 0.9573004897723999}\n",
            "semantic_frame_acc increased (0.792000 --> 0.798000).  Saving model ...\n",
            "Iteration: 100% 139/139 [00:48<00:00,  2.89it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 20\n",
            "Iteration:  14% 19/139 [00:06<00:38,  3.13it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.40it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  8.62it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  8.26it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  8.08it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  8.03it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  7.94it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:01,  7.89it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:01,  7.85it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:01<00:00,  7.47it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  7.29it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  7.17it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  7.33it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  7.50it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  7.58it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:02<00:00,  7.88it/s]\n",
            "DEV:  {'loss': 0.13216953666415066, 'intent_acc': 0.98, 'slot_accuracy': 0.764, 'slot_precision': 0.9161036036036037, 'slot_recall': 0.9497956800934034, 'slot_f1': 0.9326454571510462, 'semantic_frame_acc': 0.752, 'mean_intent_slot': 0.9563227285755231}\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Iteration: 100% 139/139 [00:47<00:00,  2.94it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 21\n",
            "Iteration:  14% 20/139 [00:06<00:38,  3.13it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.19it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  8.41it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  8.67it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  8.76it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  8.87it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  8.80it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:01,  8.90it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  8.92it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:01<00:00,  8.98it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  8.74it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  8.80it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  8.82it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  8.84it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  8.91it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  9.03it/s]\n",
            "DEV:  {'loss': 0.15069564513396472, 'intent_acc': 0.98, 'slot_accuracy': 0.82, 'slot_precision': 0.928817451205511, 'slot_recall': 0.9445417396380619, 'slot_f1': 0.9366136034732273, 'semantic_frame_acc': 0.806, 'mean_intent_slot': 0.9583068017366136}\n",
            "semantic_frame_acc increased (0.798000 --> 0.806000).  Saving model ...\n",
            "Iteration: 100% 139/139 [00:48<00:00,  2.89it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 22\n",
            "Iteration:  15% 21/139 [00:06<00:37,  3.13it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.18it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  8.40it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  8.67it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  8.61it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  8.63it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  8.52it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:01,  8.52it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  8.68it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:01<00:00,  8.64it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  8.71it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  8.81it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  8.84it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  8.89it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  8.93it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  8.92it/s]\n",
            "DEV:  {'loss': 0.14642203249968588, 'intent_acc': 0.982, 'slot_accuracy': 0.83, 'slot_precision': 0.9301260022909508, 'slot_recall': 0.9480443666082895, 'slot_f1': 0.9389997108991037, 'semantic_frame_acc': 0.818, 'mean_intent_slot': 0.9604998554495519}\n",
            "semantic_frame_acc increased (0.806000 --> 0.818000).  Saving model ...\n",
            "Iteration: 100% 139/139 [00:48<00:00,  2.89it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 23\n",
            "Iteration:  16% 22/139 [00:07<00:37,  3.13it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.13it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  8.23it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  8.51it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  8.62it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  8.75it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  8.86it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:01,  8.89it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  8.81it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:01<00:00,  8.82it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  8.77it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  8.61it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  8.75it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  8.81it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  8.87it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  8.95it/s]\n",
            "DEV:  {'loss': 0.15608829585835338, 'intent_acc': 0.976, 'slot_accuracy': 0.824, 'slot_precision': 0.9267315397824842, 'slot_recall': 0.9451255107997665, 'slot_f1': 0.9358381502890173, 'semantic_frame_acc': 0.808, 'mean_intent_slot': 0.9559190751445086}\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Iteration: 100% 139/139 [00:46<00:00,  3.00it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 24\n",
            "Iteration:  17% 23/139 [00:07<00:37,  3.12it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.46it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  8.69it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  8.78it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  8.69it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  8.79it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  8.89it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:01,  8.91it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  8.84it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:01<00:00,  8.86it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  8.90it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  8.83it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  8.85it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  8.93it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  8.86it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  9.03it/s]\n",
            "DEV:  {'loss': 0.12499618215952069, 'intent_acc': 0.976, 'slot_accuracy': 0.832, 'slot_precision': 0.9297639608520437, 'slot_recall': 0.9427904261529481, 'slot_f1': 0.9362318840579711, 'semantic_frame_acc': 0.816, 'mean_intent_slot': 0.9561159420289855}\n",
            "EarlyStopping counter: 2 out of 5\n",
            "Iteration: 100% 139/139 [00:46<00:00,  3.00it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 25\n",
            "Iteration:  17% 24/139 [00:07<00:36,  3.11it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.46it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  8.69it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  8.73it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  8.75it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  8.81it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  8.87it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:01,  8.90it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  8.92it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:01<00:00,  8.77it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  8.85it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  8.87it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  8.90it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  8.93it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  8.87it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  9.03it/s]\n",
            "DEV:  {'loss': 0.1575054470449686, 'intent_acc': 0.974, 'slot_accuracy': 0.808, 'slot_precision': 0.9241733181299886, 'slot_recall': 0.9462930531231757, 'slot_f1': 0.9351023940005769, 'semantic_frame_acc': 0.788, 'mean_intent_slot': 0.9545511970002885}\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Iteration: 100% 139/139 [00:46<00:00,  3.00it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 26\n",
            "Iteration:  18% 25/139 [00:08<00:39,  2.86it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.50it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  8.72it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  8.84it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  8.76it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  8.71it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  8.76it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:01,  8.82it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  8.86it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:01<00:00,  8.84it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  8.85it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  8.83it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  8.77it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  8.83it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  8.76it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  9.01it/s]\n",
            "DEV:  {'loss': 0.164562035119161, 'intent_acc': 0.974, 'slot_accuracy': 0.766, 'slot_precision': 0.9128724002248454, 'slot_recall': 0.9480443666082895, 'slot_f1': 0.9301260022909508, 'semantic_frame_acc': 0.746, 'mean_intent_slot': 0.9520630011454754}\n",
            "EarlyStopping counter: 4 out of 5\n",
            "Iteration: 100% 139/139 [00:47<00:00,  2.95it/s]\n",
            "Iteration:   0% 0/139 [00:00<?, ?it/s]\n",
            "Epoch 27\n",
            "Iteration:  19% 26/139 [00:08<00:36,  3.13it/s]\n",
            "Tuning metrics: semantic_frame_acc\n",
            "\n",
            "Evaluating:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:   6% 1/16 [00:00<00:01,  8.24it/s]\u001b[A\n",
            "Evaluating:  12% 2/16 [00:00<00:01,  8.51it/s]\u001b[A\n",
            "Evaluating:  19% 3/16 [00:00<00:01,  8.71it/s]\u001b[A\n",
            "Evaluating:  25% 4/16 [00:00<00:01,  8.76it/s]\u001b[A\n",
            "Evaluating:  31% 5/16 [00:00<00:01,  8.71it/s]\u001b[A\n",
            "Evaluating:  38% 6/16 [00:00<00:01,  8.82it/s]\u001b[A\n",
            "Evaluating:  44% 7/16 [00:00<00:01,  8.86it/s]\u001b[A\n",
            "Evaluating:  50% 8/16 [00:00<00:00,  8.93it/s]\u001b[A\n",
            "Evaluating:  56% 9/16 [00:01<00:00,  8.95it/s]\u001b[A\n",
            "Evaluating:  62% 10/16 [00:01<00:00,  8.96it/s]\u001b[A\n",
            "Evaluating:  69% 11/16 [00:01<00:00,  8.87it/s]\u001b[A\n",
            "Evaluating:  75% 12/16 [00:01<00:00,  8.90it/s]\u001b[A\n",
            "Evaluating:  81% 13/16 [00:01<00:00,  8.90it/s]\u001b[A\n",
            "Evaluating:  88% 14/16 [00:01<00:00,  8.79it/s]\u001b[A\n",
            "Evaluating: 100% 16/16 [00:01<00:00,  9.01it/s]\n",
            "DEV:  {'loss': 0.1636314222123474, 'intent_acc': 0.974, 'slot_accuracy': 0.802, 'slot_precision': 0.9233409610983981, 'slot_recall': 0.9422066549912435, 'slot_f1': 0.9326784166425889, 'semantic_frame_acc': 0.782, 'mean_intent_slot': 0.9533392083212944}\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "Iteration:  19% 26/139 [00:10<00:45,  2.48it/s]\n",
            " 54% 27/50 [21:23<18:13, 47.54s/it]\n",
            "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing JointPhoBERT: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing JointPhoBERT from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing JointPhoBERT from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of JointPhoBERT were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['intent_classifier.linear.weight', 'crf.end_transitions', 'slot_classifier.linear_slot.weight', 'crf.start_transitions', 'slot_classifier.linear.weight', 'slot_classifier.linear.bias', 'intent_classifier.linear.bias', 'crf.transitions']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Evaluating:   0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torchcrf/__init__.py:249: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at ../aten/src/ATen/native/TensorCompare.cpp:413.)\n",
            "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n",
            "Evaluating: 100% 28/28 [00:03<00:00,  7.36it/s]\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: UNK seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.8/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "TEST RESULTS:  {'loss': 0.18231671982045686, 'intent_acc': 0.975363941769317, 'slot_accuracy': 0.8230683090705487, 'slot_precision': 0.9198210598761184, 'slot_recall': 0.9369085173501577, 'slot_f1': 0.928286160791804, 'semantic_frame_acc': 0.8040313549832027, 'mean_intent_slot': 0.9518250512805605}\n"
          ]
        }
      ],
      "source": [
        "!bash runtime/idsf_run/run_phobert.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OI0XksYVZzFF"
      },
      "source": [
        "#####annotated new classes "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbCbCJaThcxp"
      },
      "outputs": [],
      "source": [
        "#FIRST RUN WITH SMALL COEFFICIENT\n",
        "!python trainer.py --task phoATIS_plus  --model_type distill-bert --n_epochs 30 --train_batch_size 32 --eval_batch_size 32 --rnn_num_layers 3  --device cuda --use_crf --logging_steps 140 --module_role IDSF  --intent_loss_coef 0.6 --learning_rate 3e-5 --task phoATIS_plus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdc5f_XowzMO"
      },
      "outputs": [],
      "source": [
        "#2nd RUN WITH SMALL COEFFICIENT\n",
        "!python trainer.py --from_pretrained_weights \"/content/deep-learning-tourxQA/source/model_dir/idsf_weights/phobert_30_3e-05.pt\" --pretrained --model_type phobert --n_epochs 30 --train_batch_size 32 --eval_batch_size 32 --rnn_num_layers 3  --device cuda --use_crf --logging_steps 140 --module_role IDSF  --intent_loss_coef 0.15 --learning_rate 3e-5 --task phoATIS_plus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKc__-Ed2VkJ"
      },
      "outputs": [],
      "source": [
        "#PREDICT\n",
        "!python predict.py --pretrained --model_type phobert --n_epochs 30 --train_batch_size 32 --eval_batch_size 32 --rnn_num_layers 3  --device cuda --use_crf --logging_steps 140 --module_role IDSF  --intent_loss_coef 0.15 --learning_rate 3e-5 --task phoATIS_plus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBo147cM4sW4"
      },
      "outputs": [],
      "source": [
        "!python predict.py --text_question \"Cho tớ tìm vé đi từ Huế đến Đà Nẵng \" --idsf_data_dir \"/content/deep-learning-tourxQA/data/processed/IDSF/phoATIS\" --task phoATIS  --model_type gru --n_epochs 10 --train_batch_size 32 --eval_batch_size 1 --rnn_num_layers 3  --device cuda --use_crf --logging_steps 140 --module_role IDSF  --intent_loss_coef 0.6 --learning_rate 5e-5 --task phoATIS_plus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0Yu7Pltv8Zz"
      },
      "source": [
        "####inference IDSF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEDmoTn6sAjk"
      },
      "outputs": [],
      "source": [
        "!touch input.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIm0ZrSIwE7K"
      },
      "outputs": [],
      "source": [
        "from underthesea import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wru4gK_N0Gx3"
      },
      "outputs": [],
      "source": [
        "with open(\"input.txt\", 'r') as f:\n",
        "  writer = open(\"sample_input.txt\", \"w\")\n",
        "  for line in f.readlines():\n",
        "    writer.write(word_tokenize(line, format=\"text\"))\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJQwLeh3zwt1",
        "outputId": "0c61be9a-2df0-4499-a8c7-5c16c97d005c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['tôi muốn tìm chuyến bay từ hải_phòng vào thành_phố vinh vào ngày 19 tháng 7 cho nhóm 3 người_lớn và 2 trẻ_em']"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "open(\"sample_input.txt\", \"r\").readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7cXKRKBQXfX",
        "outputId": "d370bfb0-bc06-4100-8b7d-73660031b120"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Predicting:   0% 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torchcrf/__init__.py:305: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ../aten/src/ATen/native/TensorCompare.cpp:402.)\n",
            "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n",
            "Predicting: 100% 1/1 [00:00<00:00,  1.67it/s]\n"
          ]
        }
      ],
      "source": [
        "!python predict.py --pretrained --model_type phobert --n_epochs 30 --train_batch_size 32 --eval_batch_size 32 --rnn_num_layers 3  --device cuda --use_crf --logging_steps 140 --module_role IDSF  --intent_loss_coef 0.6 --learning_rate 3e-5 --predict_task \"test example\" --task phoATIS_plus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMY09Xgf11fH",
        "outputId": "6f6b2a50-3cd4-4b58-e225-c3ab8c5a567a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<flight> -> tôi muốn tìm chuyến bay từ [hải_phòng:B-fromloc.city_name] vào [thành_phố:B-toloc.city_name] [vinh:I-toloc.city_name] vào [ngày:B-depart_date.day_number] [19:I-depart_date.day_number] [tháng:B-depart_date.month_name] [7:I-depart_date.month_name] cho [nhóm:B-num_person] [3:I-num_person] [người_lớn:I-num_person] và [2:B-num_person] [trẻ_em:I-num_person]\\n']"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "open(\"sample_output.txt\", \"r\").readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCgeBxiEzt-R"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/deep-learning-tourxQA/data/processed/IDSF/phoATIS /content/deep-learning-tourxQA/data/raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDP67QuiM6tz"
      },
      "outputs": [],
      "source": [
        "!python /content/deep-learning-tourxQA/data/raw/augment.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sQANNNmM90A"
      },
      "outputs": [],
      "source": [
        "!mv /content/deep-learning-tourxQA/data/raw/phoATIS /content/deep-learning-tourxQA/data/raw/phoATIS_plus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsLD7C3yNXrz"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/deep-learning-tourxQA/data/raw/phoATIS_plus /content/deep-learning-tourxQA/data/processed/IDSF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlvDU0pSOAsC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_Uw3iehz0Se"
      },
      "source": [
        "####inference QA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koKmIGXRz2BF",
        "outputId": "8cb5a8c4-32b4-402c-f0c9-54003b3bb60e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects:  25% (1/4)   \rUnpacking objects:  50% (2/4)   \rUnpacking objects:  75% (3/4)   \rUnpacking objects: 100% (4/4)   \rUnpacking objects: 100% (4/4), done.\n",
            "From https://github.com/baochi0212/deep-learning-tourxQA\n",
            "   23e9c05..cdf214b  feature/distillation -> origin/feature/distillation\n",
            "Updating 23e9c05..cdf214b\n",
            "Fast-forward\n",
            " source/predict.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ]
        }
      ],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1O-hrUY8z3FS",
        "outputId": "6ec083c6-f525-4d8b-c6ac-aac6cea2453b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at NlpHUST/electra-base-vn were not used when initializing ElectraModel: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "PRED cà phê, sữa, thịt gà rất nổi\n"
          ]
        }
      ],
      "source": [
        "!python predict.py --pretrained --model_type electra --pretrained_model NlpHUST/electra-base-vn --device cuda --task QA --train_batch_size 16 --eval_batch_size 32 --tuning_metric F1_score --logging_step 1000 --n_epochs 1 --module_role QA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBgtlco_bqge"
      },
      "source": [
        "###submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFsRE5t60CYh",
        "outputId": "d937506f-3e8f-4efa-c135-82c6918c7b24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRDJTyncnJ2W",
        "outputId": "4784d512-8985-4fae-e784-57d2641926e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mv: cannot create regular file '/content/drive/xlm-roberta-base_10_5e-05.pt': Operation not supported\n"
          ]
        }
      ],
      "source": [
        "!mv \"model_dir/qa_weights/xlm-roberta-base_10_5e-05.pt\" \"/content/drive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNo1cZD7tkgY",
        "outputId": "319a4b6a-b7b5-4bc4-bf17-fbd947405f14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/deep-learning-tourxQA/source/model_dir/qa_weights\n"
          ]
        }
      ],
      "source": [
        "%cd model_dir/qa_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKVQ4BNOuhjx"
      },
      "outputs": [],
      "source": [
        "!mv xlm-roberta-base_10_5e-05.pt qa_checkpoint.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwHxPg0Pt4_A"
      },
      "outputs": [],
      "source": [
        "!cp \"qa_checkpoint.pt\" /content/drive/MyDrive/DL_Group_23"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqjcmx0hualJ"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/drive/MyDrive/qa_checkpoint.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tffxFo8Eu1LE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}