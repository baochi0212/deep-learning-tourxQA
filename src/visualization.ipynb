{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xps/anaconda3/envs/deeplearning/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchcrf import CRF\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(32, 8)\n",
    "b = torch.zeros([32, 8], dtype=torch.float)\n",
    "b[0, 0] = 1\n",
    "loss = nn.BCEWithLogitsLoss(reduction='none')(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = torch.where(b != 0, loss, torch.tensor([0.]))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.where(b != 0, loss, loss*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tags = 5  # number of tags is 5\n",
    "model = CRF(num_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 3  # maximum sequence length in a batch\n",
    "batch_size = 2  # number of samples in the batch\n",
    "emissions = torch.randn(seq_length, batch_size, num_tags) #n_seq x batch x logits\n",
    "tags = torch.tensor([\n",
    "  [0, 1], [2, 4], [3, 1]\n",
    "], dtype=torch.long)  #nseq x batch\n",
    "loss = model(emissions, tags)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(30, 32, 142)\n",
    "b = torch.zeros(30, 32, dtype=torch.long)\n",
    "model = CRF(a.shape[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4717.1206, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "name = ['train', 'test', 'dev']\n",
    "for i in name:\n",
    "    for label in open(\"/home/xps/educate/code/hust/XQA/docs/src/JointIDSF/PhoATIS/word-level\" + f'/{i}/label'):\n",
    "        if label.strip() not in list:\n",
    "            list.append(label.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/home/xps/educate/code/hust/XQA/data/raw/ATIS/atis_intents_train.csv\", header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['atis_flight', 'atis_flight_time', 'atis_airfare', 'atis_aircraft',\n",
       "        'atis_ground_service', 'atis_airline', 'atis_abbreviation',\n",
       "        'atis_quantity'], dtype=object),\n",
       " 4834)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {'vietanh': 'ngu'}\n",
    "a.update({'vie anh': 'ocho'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['atis_flight', 'atis_airfare', 'atis_ground_service',\n",
       "        'atis_airline', 'atis_flight_time', 'atis_quantity',\n",
       "        'atis_abbreviation', 'atis_aircraft'], dtype=object),\n",
       " 800)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"/home/xps/educate/code/hust/XQA/data/raw/ATIS/atis_intents_test.csv\", header=None)\n",
    "test[0].unique(), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tôi muốn một chuyến bay khứ_hồi từ đồng_hới đến côn_đảo khởi_hành vào thứ tư ngày 16 tháng 6 đến côn_đảo vào buổi tối khoảng 7 giờ và trở về đồng_hới vào buổi tối ngày hôm sau khoảng 7 giờ hãng hàng_không nào có chuyến bay phù_hợp với tuyến đường đó\n"
     ]
    }
   ],
   "source": [
    "lengths = {}\n",
    "with open(\"/home/xps/educate/code/hust/XQA/data/raw/PhoATIS/word-level/train/seq.in\", 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        if len(line.strip().split(' ')) not in lengths.keys():\n",
    "            lengths[len(line.strip().split(' '))] = 1\n",
    "        else:\n",
    "            lengths[len(line.strip().split(' '))] += 1 \n",
    "        if len(line.strip().split(' ')) == 50:\n",
    "            print(line.strip()) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(lengths, key = lambda d: lengths[d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hoctro'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename('/hoa/hoctro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xps/anaconda3/envs/deeplearning/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "os.environ['dir'] = \"/home/xps/educate/code/hust/XQA/data\"\n",
    "from utils.preprocess import string2list, get_label\n",
    "from collections import Counter\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "data_dir = os.environ['dir']\n",
    "raw_dir = data_dir + '/data/raw/PhoATIS'\n",
    "processed_dir = data_dir + '/data/processed/PhoATIS'\n",
    "qa_processed = data_dir + '/data/processed/QA'\n",
    "tokenizer = AutoTokenizer.from_pretrained('NlpHUST/bert-base-vn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/home/xps/educate/code/hust/XQA/data/processed/QA/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"/home/xps/educate/code/hust/XQA/data/processed/QA/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = pd.read_csv(\"/home/xps/educate/code/hust/XQA/data/processed/QA/dev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_label(input, text, start):\n",
    "\n",
    "#     sequence_ids = input.sequence_ids()\n",
    "#     idx = 0\n",
    "#     while sequence_ids[idx] != 1:\n",
    "#             idx += 1\n",
    "#     context_start = idx\n",
    "#     while sequence_ids[idx] == 1:\n",
    "#             idx += 1\n",
    "#     context_end = idx - 1\n",
    "#     offset = input['offset_mapping']\n",
    "    \n",
    "\n",
    "#     start_positions, end_positions = [], []\n",
    "#     start_positions = []\n",
    "#     end_positions = []\n",
    "#     start_char = start\n",
    "#     end_char = start + len(text)\n",
    "#     offset = input['offset_mapping'][0]\n",
    "#     if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "#         start_positions.append(0)\n",
    "#         end_positions.append(0)\n",
    "#     else:\n",
    "#         # Otherwise it's the start and end token positions\n",
    "#         idx = context_start\n",
    "#         while idx <= context_end and offset[idx][0] <= start_char:\n",
    "#             idx += 1\n",
    "#         start_positions.append(idx - 1)\n",
    "#         idx = context_end\n",
    "#         while idx >= context_start and offset[idx][1] >= end_char:\n",
    "#             idx -= 1\n",
    "#         end_positions.append(idx + 1)\n",
    "\n",
    " \n",
    "#     return torch.tensor(start_positions, dtype=torch.long), torch.tensor(end_positions, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = True\n",
    "for i in range(len(train_df)):\n",
    "    q, a, c, t = train_df.iloc[i][['question', 'start', 'context', 'text']]\n",
    "    input = tokenizer(q.strip(), c, return_tensors='pt',\n",
    "                max_length=500,\n",
    "                truncation=\"only_second\",\n",
    "                return_offsets_mapping=True,\n",
    "                padding=\"max_length\",)\n",
    "    a, t = string2list(a, 'int'), string2list(t)\n",
    "    start, end = 0, 0\n",
    "    for i in range(len(a)):\n",
    "        s, e = get_label(input, t[0], a[0])\n",
    "        if e < s:\n",
    "            print(\"???\", s, e)\n",
    "            run = False\n",
    "            break\n",
    "        start += s \n",
    "        end += e\n",
    "    # if start == 0 or end == 0:\n",
    "    #     q, c, a, t = q, c, a, t\n",
    "    #     run = False\n",
    "    #     break\n",
    "    if not run:\n",
    "        break\n",
    "        \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Kinh đô ánh sáng nổi tiếng về lĩnh vực gì?',\n",
       " 'Paris nằm ở điểm gặp nhau của các hành trình thương mại đường bộ và đường sông, và là trung tâm của một vùng nông nghiệp giàu có. Vào thế kỷ 10, Paris đã là một trong những thành phố chính của Pháp cùng các cung điện hoàng gia, các tu viện và nhà thờ. Từ thế kỷ 12, Paris trở thành một trong những trung tâm của châu Âu về giáo dục và nghệ thuật. Thế kỷ 14, Paris là thành phố quan trọng bậc nhất của Cơ Đốc giáo và trong các thế kỷ 16, 17, đây là nơi diễn ra Cách mạng Pháp cùng nhiều sự kiện lịch sử quan trọng của Pháp và châu Âu. Đến thế kỷ 19 và 20, thành phố trở thành một trong những trung tâm văn hóa của thế giới, thủ đô của nghệ thuật và giải trí.',\n",
       " 'nghệ thuật và giải trí',\n",
       " 634,\n",
       " 'nghệ thuật và giải trí.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 3\n",
    "q, a, c, t = dev_df.iloc[i][['question', 'start', 'context', 'text']]\n",
    "input = tokenizer(q.strip(), c, return_tensors='pt',\n",
    "            max_length=500,\n",
    "            truncation=\"only_second\",\n",
    "            return_offsets_mapping=True,\n",
    "            padding=\"max_length\",)\n",
    "a, t = string2list(a, 'int'), string2list(t)\n",
    "q, c, t[0], a[0], c[a[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(634,\n",
       " 'nghệ thuật và giải trí',\n",
       " 'Kinh đô ánh sáng nổi tiếng về lĩnh vực gì?',\n",
       " 'Paris nằm ở điểm gặp nhau của các hành trình thương mại đường bộ và đường sông, và là trung tâm của một vùng nông nghiệp giàu có. Vào thế kỷ 10, Paris đã là một trong những thành phố chính của Pháp cùng các cung điện hoàng gia, các tu viện và nhà thờ. Từ thế kỷ 12, Paris trở thành một trong những trung tâm của châu Âu về giáo dục và nghệ thuật. Thế kỷ 14, Paris là thành phố quan trọng bậc nhất của Cơ Đốc giáo và trong các thế kỷ 16, 17, đây là nơi diễn ra Cách mạng Pháp cùng nhiều sự kiện lịch sử quan trọng của Pháp và châu Âu. Đến thế kỷ 19 và 20, thành phố trở thành một trong những trung tâm văn hóa của thế giới, thủ đô của nghệ thuật và giải trí.')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0], t[0], q, c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input['overflow_to_sample_mapping']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(157), tensor(172))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start, end = get_label(input, t[2], a[2])\n",
    "start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input.input_ids[0][start.item():end.item()+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = []\n",
    "\n",
    "for i in range(len(dev_df)):\n",
    "    q, a, c, t = dev_df.iloc[i][['question', 'start', 'context', 'text']]\n",
    "    a, c = string2list(a, 'int'), string2list(c)\n",
    "    length.append(len(q.strip().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.979868708971553"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(length)/len(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([432, 432, 432, 432],\n",
       " ['Năm 1871, Đức trở thành một quốc gia dân tộc khi hầu hết các quốc gia Đức thống nhất trong Đế quốc Đức do Phổ chi phối. Sau Chiến tranh thế giới thứ nhất và Cách mạng Đức 1918-1919, Đế quốc này bị thay thế bằng Cộng hòa Weimar theo chế độ nghị viện. Chế độ độc tài quốc xã được hình thành vào năm 1933, dẫn tới Chiến tranh thế giới thứ hai và một nạn diệt chủng. Sau một giai đoạn Đồng Minh chiếm đóng, hai nước Đức được thành lập: Cộng hòa Liên bang Đức và Cộng hòa Dân chủ Đức. Năm 1990, quốc gia được tái thống nhất.'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max = 0\n",
    "for i in range(len(df)):\n",
    "    item = df.iloc[i]\n",
    "    start = string2list(item['start'], type='int')\n",
    "    text = string2list(item['text'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wefwefwefwfe', 'dfsdfsdf']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"wefwefwefwfe@@@dfsdfsdf\"\n",
    "a.split(\"@@@\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaModel, AutoTokenizer\n",
    "model_checkpoint = 'vinai/phobert-base'\n",
    "# model = QAModule(model_checkpoint=model_checkpoint)\n",
    "model = RobertaModel.from_pretrained(model_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "input = tokenizer(\"DIT CON ME\", return_tensors='pt',\n",
    "        max_length=258,\n",
    "        truncation=\"only_second\",\n",
    "        padding=\"max_length\",)\n",
    "model(input_ids=input.input_ids.repeat(16, 1), attention_mask=input.attention_mask.repeat(16, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/xps/educate/code/hust/XQA/src/visualization.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/xps/educate/code/hust/XQA/src/visualization.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mdevice\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('deeplearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73fdcbcaa6b22d852c0f9bd9783ab6b1b1c25c52a0a8da76beae07513436cb85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
